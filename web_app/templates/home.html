<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>News Analysis</title>

    <!-- Bootstrap core CSS -->
    <link href="../static/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="../static/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../static/css/starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="../static/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    {{ js_resources|indent(4)|safe }}

    {{ css_resources|indent(4)|safe }}


  </head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
  <body>

  <!-- Sidebar -->
  <div class="w3-sidebar w3-light-grey w3-bar-block" style="width:8%">
    <h3 class="w3-bar-item">Menu</h3>
    <a href="#intro" class="w3-bar-item w3-button">Introduction</a>
    <a href="#data" class="w3-bar-item w3-button">Data</a>
    <a href="#about" class="w3-bar-item w3-button">About</a>
  </div>


  <div class="container">
    <h1 align="center"><strong>News Analysis</strong></h1>
    <h2>Motivations</h2>
    <p>
      The aim of this project was to provide users with tools to examine American political news and the websites that post it, in an effort to help neutralize the biases different news organization may posses.
      In an ever growing divided political climate, I think it is necessary to understand both sides of an arguement.
      News sources claim they are unbiases, but many Americans do not believe that is so.
      This project does not attempt to uncover their bias, but merely allow users to see how they cover and treat different topics.
      Opinions in news sources are not the problem, but presenting those opinions as facts is.
      This project examines how analytical, objective and opinionated certain news organizations are towards a topic.
      You will see there is a linear relationship between analysis and opinions when it comes to articles and organizations.
      This makes sense as artilces that examine a topic tend to give their opinion on the subject.
      There are, however, some outliers that mostly examine or mostly give their opinion.
      This project allows a user to decide for themselves whether they would like to read an analytical piece, opinion piece, neither or both.
      The hope is that a user can view all sides of an issue and come to a conclusion on their own about how they feel towards it.
    </p>

    <h2>Introduction</h2>
    <p>
      This project uses Latent Dirichlet Allocation (LDA) to determine topics written about in online American political articles.
      In LDA, each news article can be considered a mix of multiple topics and LDA assigns as set of topics to it with a probability of pertaining to that topic.
      Each topic has a set of words related to it, also with probabilies of being related to that topic.
      It is then assumed in LDA that articles with a high frequency of words that have high probabilities of being in a topic will themselves have a high probability of being in that topic.
      This assumption is that the topic distribution has a sparse Dirichlet prior or that articles cover a small set of topics and that topics use a small set of words frequently.
      There are, however, many words that are common in all articles, such as 'I', 'and', 'the', etc. We call these "stop-words" and they are removed before the LDA model is built.
      In this project I also got rid of other words and characters that I found unnecessary, such as characters frequent in tweets or urls.
      Also, I decided to remove all words that appear in more than 50% of articles, which helped distinguish the topics from each other more as there were many words that were included in most articles like 'Trump', 'election', 'politics', etc.
      Words that appeared in less than 20 articles were also removed so that obscure or mispelled words did not effect the model.
    </p>
    <p>
      LDA requires you to input how many topics you want it to create before creating the model. Since I am using all the articles I can get from my news source and the number of topics discussed can be any number, I had to determine how many topics to enter.
      There were several attempts to approach this decision in a scientific way, but ultimately I just made several models with varying topics and picked the one that had the most distinguishable topics.
      I believe this is an acceptable solution because the attempts I made to scientifically find a number of topics showed that there was a wide range of acceptable values.
      The first attempt was to use Hierarchical Dirichlet Process (HDP) LDA, which is an extension of LDA designed to address the issue of not knowing the number of topics before hand.
      The goal of HDP is to learn how many topics you need from the data. I used HDP to calculate 150 topics and determined the probability that each of those topics had in regards to the articles.
      Unfortunatley I did not see an obvious decision in the number of topics to pick from this.
      All topics had less than a 10% probability and decreased at a slow rate to around 5%.
      The hope was to see a steep drop in probability and then an 'elbow', where the probability leveled off and we could determine the number of topics to be there.
      The second attempt to resolve this issue was using a "coherence" metric.
      The idea behind this is that some topics are more coherent than other or in other words people can interpret what one topic is over others.
      To determine a topics coherence, I model was created using data collected from people who were told to rate a topic's coherence.
      That and a web of word similarities is used. More about that can be learned <a href="http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf">here</a>.
      I used this metric on LDA models created using topic number from 5 to 80.
      The coherence value did not vary much between any of the models.
    </p>

    <h2>Example</h2>
    <p>
      Below is the same graph you will see when you click the "Topic Selector" tab above.
      The left side of the graph is a visualization of the topics that have been determines using Latent Dirichlet Allocation (LDA).
      The right side shows you the top 20 words associated with the topic you have selected. To learn more about this please go to the "Topic Selector" page.
      Below the graph is a table of my personal labels for the topics I felt I could reasonably discern.
      These are simply recommendations for what I believe the topic is discussing and I encourage you to decide that for yourself.
    </p>

    {{ pyLDAvis_html | safe }}


    <div>
    <ol class="columns" data-columns="2">
        <li value=1>Robert Mueller/ FBI Special Counsel</li>
        <li value=4>Voter Fraud</li>
        <li value=5>Jon Ossoff Congressional Campaign</li>
        <li value=9>Advertising</li>
        <li value=11>Trump's Covfefe Tweet</li>
        <li value=13>Health Insurance</li>
        <li value=16>Comey/Sessions Testimonies</li>
        <li value=17>Trump Budget Proposal</li>
        <li value=18>North Korean Missile Tests</li>
        <li value=20>Birth Control</li>
        <li value=22>Alex Jones' Interview with Megyn Kelly</li>
        <li value=28>Climate Change/ Paris Agreement</li>
        <li value=29>Trump Impeachment</li>
        <li value=30>Greg Gianforte Body-Slamming Reporter</li>
        <li value=31>Trump's Travel Ban</li>
        <li value=33>Manchester Terror Attack</li>
        <li value=35>Trump's Middle East Trips</li>
        <li value=36>Russian Probe</li>
        <li value=37>Immigration/ Deportation</li>
        <li value=40>Protestors Beaten by Turkish President's Security Detail</li>
        <li value=41>Shooting at GOP Baseball Game</li>
        <li value=42>London Mayor Statment/ Trump's Response to it</li>
        <li value=43>Comey's Testimony Before Congress</li>
        <li value=44>GOP Health Care Bill</li>
        <li value=45>NATO</li>
        <li value=46>Former CIA Director John Brennan testimony</li>
        <li value=47>Cuba</li>
        <li value=48>FOX News</li>
        <li value=49>Supreme Court Nominee Neil Gorsuch</li>
        <li value=50>Housing Crisis</li>
        <li value=51>Middle East News</li>
        <li value=52>Trump's Communication with Russia</li>
        <li value=53>Puerto Rico Referendum</li>
    </ol>
    </div>

    <form action = "/graphs_input" method="POST" >
        <ul >
            <strong>Learn more about a topic by entering its' number here: </strong><input name="topic" type ="number" />
            <input type ="submit" value="submit" /> </li>
        </ul>
    </form>
    <hr>

    <h2>Topic 30: Congressman Greg Gianforte "body-slams" a Reporter</h2>
    <p>
      From now on I will be using Topic 30 as an example of the analysis I have made for every topic.
      I chose this topic because I believe it illustrates what I have tried to accomplish with this project very well and because I do not think anyone would dispute the topic description I have provided since this topic is very specific.
    </p>
    <h3>Summary of Incident from Wikipedia</h3>
    <p>
      On May 24, 2017, the day before the U.S. House special election, Ben Jacobs, a political reporter for The Guardian newspaper who was covering the election, said that Gianforte assaulted him. Jacobs said that Gianforte "bodyslammed" him to the floor and broke the reporter's glasses. The Gianforte campaign was initially unapologetic, blaming the reporter, disputing the allegations, saying that Jacobs grabbed Gianforte's wrist, causing them both to fall to the ground. However, an audio recording of the incident appeared to support Jacobs's statement, and other reporters who were present at the scene corroborated Jacobs' version of events.
    </p>
    <p>
    According to Fox News reporter Alicia Acuna, who witnessed the incident, "Gianforte grabbed Jacobs by the neck with both hands and slammed him into the ground," then "began punching the man" and "yelling something to the effect of 'I'm sick and tired of this!'"; Acuna added that Jacobs was not showing "physical aggression" prior to the altercation. Following the incident, Jacobs went to the hospital for x-rays.
    </p>
    <p>
    Gianforte was cited for misdemeanor assault by the Gallatin County Sheriff and has been ordered to appear in court regarding his actions. Three of Montana's largest newspapers, including the Billings Gazette, the largest in the state, the Missoulian and the Independent Record, all rescinded their endorsements of Gianforte in the wake of the incident. Speaker Paul Ryan and other members of Congress urged Gianforte to apologize for his assault.
    </p>
    <p>
    Gianforte won the special election on May 25. During Gianforte's acceptance speech that evening, he apologized to Jacobs and the Fox News crew for his assault. On June 7 Gianforte made a written apology to Jacobs and donated $50,000 to the Committee to Protect Journalists, in return, Jacobs agreed to not pursue a civil claim against Gianforte.
    </p>
    <p>
    On June 12, 2017, Gianforte pleaded guilty and was originally sentenced to four days in jail, to be completed in part through a work program. But because Gianforte was guilty of an assault charge, he was ineligible for the work program. The judge then switched the sentence to 40 hours of community service, 20 hours of anger management, 180-day deferred sentence, and a $300 fine along with an $85 court fee.
    </p>

    <h3>Analysis</h3>
    <h4>Coverage</h4>
    <p>
      First, I will go over the coverage of this topic by news source.
      As stated in the summary, Gianforte assulted the reporter on May 24th and plead guilty to the assult on June 12.
      Below is a plot of the coverage of this topic by news site. As you can see there is a rise in coverage starting on May 23rd (the day the incident occured), peaking on May 24th (the day of the House special election), and a second peak on June 12th (the day of Gianforte's sentencing).
      Some sites had more coverage than others, such as Fox having the most, which may be due to a Fox reporter witnessing the incident.
    </p>

    <img src="../static/img/coverage_plots/coverage_plot_by_topic30_2017-06-18_55_topics_400_passes.png" class="img-responsive" alt="Cinque Terre" width="1200" height="800">

    <h4>Mood</h4>

    <img src="../static/img/mood_plots/mood_by_site_plot_by_topic30_2017-06-18_55_topics_400_passes.png" class="img-responsive" alt="Cinque Terre" width="1200" height="800">

    <h4>Sentiment</h4>

    <img src="../static/img/pos_neg_plots/pos_neg_plot_by_site_by_topic30_2017-06-18_55_topics_400_passes.png" class="img-responsive" alt="Cinque Terre" width="1200" height="800">

    <p>
      Other resources provided are coverage, mood and sentiment analyses. The coverage analysis allows you to see how each of the 12 sites used in this project covered a certain topic.
      The mood analysis uses IBM Watson's ToneAnalyzerV3 to get the probabilities of 5 different moods: Anger, Fear, Disgust, Sadness and Joy.
      These tones are based on the theory of research pscholinguistics, a field of research that explores the relationship between linguistic behavior and psychological theories.
      It is theorized that we can determine the tone of a person's speech by examining the words they use and the frequency at which they use them.
      Since it is people who write these articles, it is possible that they're tone is reflected in their writing and by extension their opinion or bias.
      The overall tone of the article was discussed
    </p>
  </div><!-- /.container -->


    <nav class="navbar navbar-inverse navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand">News Analysis</a>
            </div>
            <div id="navbar" class="collapse navbar-collapse">
              <ul class="nav navbar-nav">
                <li>
                    <a href="/">Home</a>
                </li>
                <li>
                    <a href="/graphs">Topic Selector</a>
                </li>
                <li>
                    <a href="/input">Predict</a>
                </li>
                <li>
                    <a href="/about">About</a>
                </li>
                <li>
                    <a href="/contact">Contact</a>
                </li>
              </ul>
            </div><!--/.nav-collapse -->
      </div>
    </nav>



    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../static/js/jquery.min.js"><\/script>')</script>
    <script src="../static/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../static/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
